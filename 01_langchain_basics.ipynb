{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288ce9a8",
   "metadata": {},
   "source": [
    "# LangChain Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002d92f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installing the required libraries\n",
    "pip install -r ./requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff28727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip - installs the packages in the base environment\n",
    "# pip - installs the packages in the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf2f431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.0.190\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://www.github.com/hwchase17/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\users\\sthor\\anaconda3\\envs\\nlp\\lib\\site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, numexpr, numpy, openapi-schema-pydantic, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14256a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upgrading langchain\n",
    "pip install langchain --upgrade -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4407a3a",
   "metadata": {},
   "source": [
    "#### Python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9420415",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c5f778ca-37d7-4a67-a01b-28afc3feee57'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# loading the API Keys (OpenAI, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "os.environ.get('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29231e2",
   "metadata": {},
   "source": [
    "### LLM Models (Wrappers): GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d37cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOpenAI\u001b[0m\n",
      "Params: {'model_name': 'text-davinci-003', 'temperature': 0.7, 'max_tokens': 512, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0, 'n': 1, 'request_timeout': None, 'logit_bias': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=512)\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d355809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Quantum mechanics is a physical theory that describes the behavior of matter and energy at the atomic and subatomic level.\n"
     ]
    }
   ],
   "source": [
    "output = llm('explain quantum mechanics in one sentence')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e29c5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(llm.get_num_tokens('explain quantum mechanics in one sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00248e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['... is the capital of France.', \n",
    "                   'What is the formula for the area of a circle?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b98fd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Generation(text='\\n\\nParis.', generation_info={'finish_reason': 'stop', 'logprobs': None})], [Generation(text='\\n\\nThe formula for the area of a circle is A = πr², where r is the radius of the circle and A is the area of the circle.', generation_info={'finish_reason': 'stop', 'logprobs': None})]]\n"
     ]
    }
   ],
   "source": [
    "print(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0725e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Paris.\n"
     ]
    }
   ],
   "source": [
    "print(output.generations[0][0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7703b86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "779b3a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm.generate(['Write an orignal tagline for a burger restaurant'] * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3cdfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"Satisfy Your Burger Cravings at Our Table!\"\n",
      "\n",
      "\"Burgers So Good, They'll Make Your Taste Buds Sing!\"\n",
      "\n",
      "\"Taste the Juiciness of Our Burgers - Freshly Grilled Every Time!\""
     ]
    }
   ],
   "source": [
    "for o in output.generations:\n",
    "    print(o[0].text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ee709",
   "metadata": {},
   "source": [
    "### ChatModels: GPT-3.5-Turbo and GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "054eadaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import(\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9bdecaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5, max_tokens=1024)\n",
    "messages = [\n",
    "    SystemMessage(content='You are a physicist and respond only in German.'),\n",
    "    HumanMessage(content='explain quantum mechanics in one sentence')\n",
    "]\n",
    "output = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "761e06dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantenmechanik beschreibt das Verhalten von Teilchen auf subatomarer Ebene und ermöglicht die Berechnung von Wahrscheinlichkeiten für verschiedene Ereignisse.\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3ad29b",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a31ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "612ed8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['virus', 'language'] output_parser=None partial_variables={} template='You are an experienced virologist.\\nWrite a few sentences about the following {virus} in {language}.' template_format='f-string' validate_template=True\n"
     ]
    }
   ],
   "source": [
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b28accc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "HIV ist ein Virus, das Immunschwäche-Virus (Human Immundefizienz Virus) heißt. Es beschädigt die Immunzellen des Körpers und macht ihn anfällig für viele andere Krankheiten. HIV wird durch sexuellen Kontakt, das Teilen von Nadeln und Bluttransfusionen übertragen. Es ist eine chronische, lebensbedrohliche Erkrankung, die ohne angemessene Behandlung zu AIDS führen kann.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0.7)\n",
    "output = llm(prompt.format(virus='HIV', language='German'))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025d9b84",
   "metadata": {},
   "source": [
    "### Simple Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd1e5278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0.5)\n",
    "template = '''You are an experienced virologist.\n",
    "Write a few sentences about the following {virus} in {language}.'''\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['virus', 'language'],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "output = chain.run({'virus': 'HSV', 'language': 'french'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be42818a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le HSV, ou le virus de l'herpès simplex, est un virus à ADN qui infecte les humains. Il existe deux types principaux de HSV : le HSV-1, qui provoque généralement des lésions orales, et le HSV-2, qui est principalement responsable des infections génitales. Le HSV peut être transmis par contact direct avec une personne infectée ou par le biais de fluides corporels. Bien qu'il ne puisse pas être guéri, il existe des traitements antiviraux qui peuvent aider à réduire les symptômes et à prévenir les récidives.\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f283cc13",
   "metadata": {},
   "source": [
    "### Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d68115d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\n",
      "\n",
      "def softmax(x): \n",
      "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
      "    e_x = np.exp(x - np.max(x)) \n",
      "    return e_x / e_x.sum()\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mThe function `softmax(x)` takes a numpy array `x` as input and returns another numpy array which contains the softmax values for each set of scores in `x`. \n",
      "\n",
      "The softmax function is often used in machine learning to convert a set of numerical values into a probability distribution. It assigns a probability to each value in such a way that the sum of these probabilities is equal to 1. \n",
      "\n",
      "The function first calculates the exponential of each value in `x` by subtracting the maximum value in `x` from each element prior to applying the exponential function. By subtracting the maximum value, the function prevents numerical instability that can occur when exponentiating large numbers.\n",
      "\n",
      "The resulting exponential values are then divided element-wise by the sum of all exponential values in order to normalize the values and make them sum to 1. This is done by dividing each element by the sum of the exponential values.\n",
      "\n",
      "The function returns the resulting array of normalized values, which represents the softmax values for each set of scores in `x`.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "llm1 = OpenAI(model_name='text-davinci-003', temperature=0.7, max_tokens=1024)\n",
    "prompt1 = PromptTemplate(\n",
    "    input_variables=['concept'],\n",
    "    template='''You are an experienced scientist and Python programmer.\n",
    "    Write a function that implements the concept of {concept}.'''\n",
    ")\n",
    "chain1 = LLMChain(llm=llm1, prompt=prompt1)\n",
    "\n",
    "\n",
    "llm2 = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.2)\n",
    "prompt2 = PromptTemplate(\n",
    "    input_variables=['function'],\n",
    "    template='Given the Python function {function}, describe it as detailed as possible.'\n",
    ")\n",
    "chain2 = LLMChain(llm=llm2, prompt=prompt2)\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2], verbose=True)\n",
    "output = overall_chain.run('softmax')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a9c39",
   "metadata": {},
   "source": [
    "### LangChain Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "631fd9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool  \n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "115e2fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the power operator\n",
      "Action: Python REPL\n",
      "Action Input: print(5.1 ** 7.3)\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m146306.05007233328\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: 146306.05007233328\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'146306.05007233328'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "agent_executor = create_python_agent(\n",
    "    llm=llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")\n",
    "# agent_executor.run('Calculate the square root of the factorial of 20 \\\n",
    "# and display it with 4 decimal points')\n",
    "\n",
    "agent_executor.run('what is the answer to 5.1 ** 7.3?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0af1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
